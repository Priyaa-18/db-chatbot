# Enterprise Database Chatbot

A production-ready LLM-based chatbot for querying enterprise databases (Snowflake, Databricks, etc.) using natural language.

## Features

- ğŸ” **Schema Discovery**: Automatic database schema introspection
- ğŸ¤– **AI-Powered SQL Generation**: Natural language to SQL using LLMs
- âœ… **Query Validation**: Syntax checking and cost estimation
- ğŸš€ **Multi-Database Support**: Snowflake, Databricks, PostgreSQL, MySQL, and more
- ğŸ“Š **Visualization**: Automatic chart generation from query results
- ğŸ”’ **Security**: Role-based access control and query safety checks
- ğŸ“ **Audit Logging**: Full query history and user tracking

## Architecture

```
User Query â†’ Orchestrator
              â†“
         State Manager
              â†“
    [Schema Agent] â†’ Get relevant tables/columns
              â†“
    [SQL Generation Agent] â†’ Generate SQL with LLM
              â†“
    [Validation Agent] â†’ Check syntax & safety
              â†“
    [Execution Agent] â†’ Run query on database
              â†“
    [Visualization Agent] â†’ Generate charts
              â†“
         Response
```

## Installation

### 1. Clone and Setup
```bash
cd enterprise-db-chatbot
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure Environment
Create a `.env` file:

```env
# LLM Configuration
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key
LLM_PROVIDER=anthropic  # or 'openai'
LLM_MODEL=claude-sonnet-4-20250514

# Database Configuration - Snowflake
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_user
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_DATABASE=your_database
SNOWFLAKE_SCHEMA=your_schema
SNOWFLAKE_WAREHOUSE=your_warehouse
SNOWFLAKE_ROLE=your_role

# Database Configuration - Databricks
DATABRICKS_SERVER_HOSTNAME=your_host.databricks.com
DATABRICKS_HTTP_PATH=/sql/1.0/endpoints/xxxxx
DATABRICKS_TOKEN=your_token
DATABRICKS_CATALOG=your_catalog
DATABRICKS_SCHEMA=your_schema

# Application Settings
MAX_QUERY_ROWS=10000
QUERY_TIMEOUT_SECONDS=300
LOG_LEVEL=INFO
```

### 3. Run Examples
```bash
# Run example chatbot
python examples/run_chatbot.py

# Run with specific database
python examples/run_chatbot.py --database snowflake
python examples/run_chatbot.py --database databricks
```

## Usage

### Basic Usage

```python
from src.orchestrator import ChatbotOrchestrator
from src.config import Settings

# Initialize
settings = Settings()
chatbot = ChatbotOrchestrator(settings)

# Query database
response = await chatbot.process_query(
    user_query="Show me top 10 customers by revenue",
    user_id="user123"
)

print(f"SQL: {response.sql}")
print(f"Results: {response.data}")
print(f"Visualization: {response.chart_html}")
```

### Advanced Usage with Context

```python
# Multi-turn conversation with context
context = ConversationContext(user_id="user123")

response1 = await chatbot.process_query(
    "Show me sales by region",
    context=context
)

# Follow-up query uses context
response2 = await chatbot.process_query(
    "Now filter for last quarter",
    context=context
)
```

## Project Structure

```
enterprise-db-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ models.py              # Data models (Pydantic)
â”‚   â”œâ”€â”€ orchestrator.py        # Main orchestration logic
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ schema_agent.py    # Schema discovery
â”‚   â”‚   â”œâ”€â”€ sql_agent.py       # SQL generation
â”‚   â”‚   â”œâ”€â”€ validation_agent.py # Query validation
â”‚   â”‚   â”œâ”€â”€ execution_agent.py # Query execution
â”‚   â”‚   â””â”€â”€ visualization_agent.py # Chart generation
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ base.py            # LLM base interface
â”‚   â”‚   â”œâ”€â”€ openai_provider.py # OpenAI implementation
â”‚   â”‚   â””â”€â”€ anthropic_provider.py # Anthropic implementation
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ base.py            # Database base interface
â”‚   â”‚   â”œâ”€â”€ snowflake_db.py    # Snowflake connector
â”‚   â”‚   â””â”€â”€ databricks_db.py   # Databricks connector
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py          # Structured logging
â”‚       â””â”€â”€ security.py        # Security utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ run_chatbot.py         # Example usage
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Security Considerations

1. **Query Safety**
   - Automatic row limits
   - Timeout enforcement
   - No DROP/DELETE/TRUNCATE allowed by default
   - SQL injection prevention

2. **Access Control**
   - User-based permissions
   - Database-level authentication
   - Audit logging of all queries

3. **Data Privacy**
   - Schema metadata only sent to LLM
   - No actual data sent to LLM
   - Results filtered by user permissions

## Testing

```bash
# Run all tests
pytest

# Run specific test suite
pytest tests/test_agents.py

# Run with coverage
pytest --cov=src tests/
```

## Performance Optimization

- Connection pooling for databases
- Schema caching with TTL
- Query result pagination
- Async execution for I/O operations

## Monitoring

All operations are logged with structured logging:
- Query execution time
- LLM token usage
- Database connection metrics
- Error rates and types

## Extending

### Add New Database
1. Create connector in `src/database/`
2. Implement `DatabaseConnector` interface
3. Add configuration in `config.py`

### Add New LLM Provider
1. Create provider in `src/llm/`
2. Implement `LLMProvider` interface
3. Add to provider factory

### Custom Validation Rules
1. Extend `ValidationAgent`
2. Add custom rules in `validate_query()`

## License

MIT License

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new features
4. Submit a pull request

## Support

For issues and questions:
- GitHub Issues: [Link to repo]
- Documentation: [Link to docs]
